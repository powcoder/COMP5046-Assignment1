{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "siAIwRRGUtWW"
   },
   "source": [
    "# Lab06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHbXdZ0b7_-W"
   },
   "source": [
    "# POS Tagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2Yuq_ck8lzM"
   },
   "source": [
    "## Regular Expressioon Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "J_SNkGVsftLK",
    "outputId": "f4d61281-7af7-4d1e-d3db-de55a1a47469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7VMB4D7Vfipk"
   },
   "outputs": [],
   "source": [
    " patterns = [\n",
    "        (r'.*ing$', 'VBG'),               # gerunds\n",
    "        (r'.*ed$', 'VBD'),                # simple past\n",
    "        (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "        (r'.*ould$', 'MD'),               # modals\n",
    "        (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "        (r'.*s$', 'NNS'),                 # plural nouns\n",
    "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "        (r'.*', 'NN')                     # nouns (default)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "ejmC2tSLk3dA",
    "outputId": "ef2714d4-417d-43a9-f289-5e8884d95e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.']\n",
      "[('``', 'NN'), ('Only', 'NN'), ('a', 'NN'), ('relative', 'NN'), ('handful', 'NN'), ('of', 'NN'), ('such', 'NN'), ('reports', 'NNS'), ('was', 'NNS'), ('received', 'VBD'), (\"''\", 'NN'), (',', 'NN'), ('the', 'NN'), ('jury', 'NN'), ('said', 'NN'), (',', 'NN'), ('``', 'NN'), ('considering', 'VBG'), ('the', 'NN'), ('widespread', 'NN'), ('interest', 'NN'), ('in', 'NN'), ('the', 'NN'), ('election', 'NN'), (',', 'NN'), ('the', 'NN'), ('number', 'NN'), ('of', 'NN'), ('voters', 'NNS'), ('and', 'NN'), ('the', 'NN'), ('size', 'NN'), ('of', 'NN'), ('this', 'NNS'), ('city', 'NN'), (\"''\", 'NN'), ('.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "print(brown_sents[3])\n",
    "print(regexp_tagger.tag(brown_sents[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V8wT_6a7k63S",
    "outputId": "8c7cd109-79f5-4a18-d172-090a7af340ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20326391789486245"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wYPlTCtt8s9L",
    "outputId": "0f019875-ddb6-4090-d000-cf36108da50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'NNS'), ('race', 'NN'), ('is', 'NNS'), ('awesome', 'NN'), (',', 'NN'), ('I', 'NN'), ('want', 'NN'), ('to', 'NN'), ('race', 'NN'), ('too', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "raw = 'This race is awesome, I want to race too'\n",
    "tokens = word_tokenize(raw)\n",
    "\n",
    "print(regexp_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GLU4cC8r49g"
   },
   "source": [
    "# Hidden Markov Models \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "w-Uuv3D5YhhS",
    "outputId": "d2b6e9f5-cd5e-4676-a086-96a6e4510735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Hidden Markov Models in Python\n",
    "# Katrin Erk, March 2013 updated March 2016\n",
    "#\n",
    "# This HMM addresses the problem of part-of-speech tagging. It estimates\n",
    "# the probability of a tag sequence for a given word sequence as follows:\n",
    "#\n",
    "# Say words = w1....wN\n",
    "# and tags = t1..tN\n",
    "#\n",
    "# then\n",
    "# P(tags | words) is_proportional_to  product P(ti | t{i-1}) P(wi | ti)\n",
    "#\n",
    "# To find the best tag sequence for a given sequence of words,\n",
    "# we want to find the tag sequence that has the maximum P(tags | words)\n",
    "import nltk\n",
    "import sys\n",
    "nltk.download('brown')\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "TO_rZxt1wv2z",
    "outputId": "2409f87f-d4e9-4de3-aa35-2b323e0e41d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an adjective (JJ) being 'new' is 0.01472344917632025\n",
      "The probability of a verb (VB) being 'duck' is 6.042713350943527e-05\n",
      "If we have just seen 'DT', the probability of 'NN' is 0.5057722522030194\n",
      "If we have just seen 'VB', the probability of 'JJ' is 0.016885067592065053\n",
      "If we have just seen 'VB', the probability of 'NN' is 0.10970977711020183\n"
     ]
    }
   ],
   "source": [
    "# Estimating P(wi | ti) from corpus data using Maximum Likelihood Estimation (MLE):\n",
    "# P(wi | ti) = count(wi, ti) / count(ti)\n",
    "#\n",
    "# We add an artificial \"start\" tag at the beginning of each sentence, and\n",
    "# We add an artificial \"end\" tag at the end of each sentence.\n",
    "# So we start out with the brown tagged sentences,\n",
    "# add the two artificial tags,\n",
    "# and then make one long list of all the tag/word pairs.\n",
    "\n",
    "brown_tags_words = []\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "\n",
    "for sent in brown_tagged_sents:\n",
    "    # sent is a list of word/tag pairs\n",
    "    # add START/START at the beginning\n",
    "    brown_tags_words.append( (\"START\", \"START\") )\n",
    "    # then all the tag/word pairs for the word/tag pairs in the sentence.\n",
    "    # shorten tags to 2 characters each\n",
    "    brown_tags_words.extend([ (tag[:2], word) for (word, tag) in sent ])\n",
    "    # then END/END\n",
    "    brown_tags_words.append( (\"END\", \"END\") )\n",
    "\n",
    "# conditional frequency distribution\n",
    "cfd_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "# conditional probability distribution\n",
    "cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, nltk.MLEProbDist)\n",
    "\n",
    "print(\"The probability of an adjective (JJ) being 'new' is\", cpd_tagwords[\"JJ\"].prob(\"new\"))\n",
    "print(\"The probability of a verb (VB) being 'duck' is\", cpd_tagwords[\"VB\"].prob(\"duck\"))\n",
    "\n",
    "# Estimating P(ti | t{i-1}) from corpus data using Maximum Likelihood Estimation (MLE):\n",
    "# P(ti | t{i-1}) = count(t{i-1}, ti) / count(t{i-1})\n",
    "brown_tags = [tag for (tag, word) in brown_tags_words ]\n",
    "\n",
    "# make conditional frequency distribution:\n",
    "# count(t{i-1} ti)\n",
    "cfd_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
    "# make conditional probability distribution, using\n",
    "# maximum likelihood estimate:\n",
    "# P(ti | t{i-1})\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)\n",
    "\n",
    "print(\"If we have just seen 'DT', the probability of 'NN' is\", cpd_tags[\"DT\"].prob(\"NN\"))\n",
    "print( \"If we have just seen 'VB', the probability of 'JJ' is\", cpd_tags[\"VB\"].prob(\"DT\"))\n",
    "print( \"If we have just seen 'VB', the probability of 'NN' is\", cpd_tags[\"VB\"].prob(\"NN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "jaetc1FSsgLW",
    "outputId": "d0e4bf37-b4d9-4a2e-cf40-3f7cb18fbe29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PP': 0.0, ')': 0.0, 'JJ': 0.0, '--': 0.0, 'END': 0.0, ')-': 0.0, 'HV': 0.0, 'WR': 0.0, '*-': 0.0, '``': 0.0, 'CS': 0.0, 'UH': 0.0, 'NI': 0.0, 'PN': 0.0, 'WD': 0.0, 'CC': 0.0, ',-': 0.0, '.': 0.0, '*': 0.0, \"''\": 0.0, ':': 0.0, 'DO': 0.0, 'QL': 0.0, 'NR': 0.0, 'FW': 0.0, 'VB': 0.0, 'AB': 0.0, 'MD': 0.0, 'WP': 0.0, 'CD': 0.0, 'BE': 0.0, 'AP': 0.0, 'WQ': 0.0, 'NP': 0.0, ',': 0.0, 'RB': 0.0, 'AT': 0.0, 'RP': 0.0, ':-': 0.0, 'RN': 0.0, 'DT': 0.0033218181276236437, 'IN': 0.0, 'OD': 0.0, \"'\": 0.0, 'TO': 0.0, 'NN': 0.0, '(-': 0.0, '(': 0.0, 'EX': 0.0, '.-': 0.0}\n",
      "{'PP': 'START', ')': 'START', 'JJ': 'START', '--': 'START', 'END': 'START', ')-': 'START', 'HV': 'START', 'WR': 'START', '*-': 'START', '``': 'START', 'CS': 'START', 'UH': 'START', 'NI': 'START', 'PN': 'START', 'WD': 'START', 'CC': 'START', ',-': 'START', '.': 'START', '*': 'START', \"''\": 'START', ':': 'START', 'DO': 'START', 'QL': 'START', 'NR': 'START', 'FW': 'START', 'VB': 'START', 'AB': 'START', 'MD': 'START', 'WP': 'START', 'CD': 'START', 'BE': 'START', 'AP': 'START', 'WQ': 'START', 'NP': 'START', ',': 'START', 'RB': 'START', 'AT': 'START', 'RP': 'START', ':-': 'START', 'RN': 'START', 'DT': 'START', 'IN': 'START', 'OD': 'START', \"'\": 'START', 'TO': 'START', 'NN': 'START', '(-': 'START', '(': 'START', 'EX': 'START', '.-': 'START'}\n",
      "Word 'This' current best two-tag sequence: START DT\n",
      "Word 'race' current best two-tag sequence: DT NN\n",
      "Word 'is' current best two-tag sequence: NN BE\n",
      "Word 'awesome' current best two-tag sequence: BE JJ\n",
      "Word ',' current best two-tag sequence: JJ ,\n",
      "Word 'I' current best two-tag sequence: , PP\n",
      "Word 'want' current best two-tag sequence: PP VB\n",
      "Word 'to' current best two-tag sequence: VB TO\n",
      "Word 'race' current best two-tag sequence: IN NN\n",
      "Word 'too' current best two-tag sequence: VB QL\n",
      "The sentence was: This race is awesome , I want to race too \n",
      "\n",
      "The best tag sequence is: START DT NN BE JJ , PP VB TO VB RB END \n",
      "\n",
      "The probability of the best tag sequence is: 3.9954320581626204e-33\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# Viterbi:\n",
    "# If we have a word sequence, what is the best tag sequence?\n",
    "#\n",
    "# The method above lets us determine the probability for a single tag sequence.\n",
    "# But in order to find the best tag sequence, we need the probability\n",
    "# for _all_ tag sequence.\n",
    "# What Viterbi gives us is just a good way of computing all those many probabilities\n",
    "# as fast as possible.\n",
    "\n",
    "# what is the list of all tags?\n",
    "distinct_tags = set(brown_tags)\n",
    "\n",
    "sentence = [\"This\", \"race\", \"is\", \"awesome\", \",\", \"I\", \"want\", \"to\", \"race\", \"too\" ]\n",
    "#sentence = [\"I\", \"saw\", \"her\", \"duck\" ]\n",
    "sentlen = len(sentence)\n",
    "\n",
    "# viterbi:\n",
    "# for each step i in 1 .. sentlen,\n",
    "# store a dictionary\n",
    "# that maps each tag X\n",
    "# to the probability of the best tag sequence of length i that ends in X\n",
    "viterbi = [ ]\n",
    "\n",
    "# backpointer:\n",
    "# for each step i in 1..sentlen,\n",
    "# store a dictionary\n",
    "# that maps each tag X\n",
    "# to the previous tag in the best tag sequence of length i that ends in X\n",
    "backpointer = [ ]\n",
    "\n",
    "first_viterbi = { }\n",
    "first_backpointer = { }\n",
    "for tag in distinct_tags:\n",
    "    # don't record anything for the START tag\n",
    "    if tag == \"START\": continue\n",
    "    first_viterbi[ tag ] = cpd_tags[\"START\"].prob(tag) * cpd_tagwords[tag].prob( sentence[0] )\n",
    "    first_backpointer[ tag ] = \"START\"\n",
    "\n",
    "print(first_viterbi)\n",
    "print(first_backpointer)\n",
    "    \n",
    "viterbi.append(first_viterbi)\n",
    "backpointer.append(first_backpointer)\n",
    "\n",
    "currbest = max(first_viterbi.keys(), key = lambda tag: first_viterbi[ tag ])\n",
    "print( \"Word\", \"'\" + sentence[0] + \"'\", \"current best two-tag sequence:\", first_backpointer[ currbest], currbest)\n",
    "# print( \"Word\", \"'\" + sentence[0] + \"'\", \"current best tag:\", currbest)\n",
    "\n",
    "for wordindex in range(1, len(sentence)):\n",
    "    this_viterbi = { }\n",
    "    this_backpointer = { }\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    \n",
    "    for tag in distinct_tags:\n",
    "        # don't record anything for the START tag\n",
    "        if tag == \"START\": continue\n",
    "\n",
    "        # if this tag is X and the current word is w, then \n",
    "        # find the previous tag Y such that\n",
    "        # the best tag sequence that ends in X\n",
    "        # actually ends in Y X\n",
    "        # that is, the Y that maximizes\n",
    "        # prev_viterbi[ Y ] * P(X | Y) * P( w | X)\n",
    "        # The following command has the same notation\n",
    "        # that you saw in the sorted() command.\n",
    "        best_previous = max(prev_viterbi.keys(),\n",
    "                            key = lambda prevtag: \\\n",
    "            prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex]))\n",
    "\n",
    "        # Instead, we can also use the following longer code:\n",
    "        # best_previous = None\n",
    "        # best_prob = 0.0\n",
    "        # for prevtag in distinct_tags:\n",
    "        #    prob = prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex])\n",
    "        #    if prob > best_prob:\n",
    "        #        best_previous= prevtag\n",
    "        #        best_prob = prob\n",
    "        #\n",
    "        this_viterbi[ tag ] = prev_viterbi[ best_previous] * \\\n",
    "            cpd_tags[ best_previous ].prob(tag) * cpd_tagwords[ tag].prob(sentence[wordindex])\n",
    "        this_backpointer[ tag ] = best_previous\n",
    "\n",
    "    currbest = max(this_viterbi.keys(), key = lambda tag: this_viterbi[ tag ])\n",
    "    print( \"Word\", \"'\" + sentence[ wordindex] + \"'\", \"current best two-tag sequence:\", this_backpointer[ currbest], currbest)\n",
    "    # print( \"Word\", \"'\" + sentence[ wordindex] + \"'\", \"current best tag:\", currbest)\n",
    "\n",
    "\n",
    "    # done with all tags in this iteration\n",
    "    # so store the current viterbi step\n",
    "    viterbi.append(this_viterbi)\n",
    "    backpointer.append(this_backpointer)\n",
    "\n",
    "\n",
    "# done with all words in the sentence.\n",
    "# now find the probability of each tag\n",
    "# to have \"END\" as the next tag,\n",
    "# and use that to find the overall best sequence\n",
    "prev_viterbi = viterbi[-1]\n",
    "best_previous = max(prev_viterbi.keys(),\n",
    "                    key = lambda prevtag: prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "prob_tagsequence = prev_viterbi[ best_previous ] * cpd_tags[ best_previous].prob(\"END\")\n",
    "\n",
    "# best tagsequence: we store this in reverse for now, will invert later\n",
    "best_tagsequence = [ \"END\", best_previous ]\n",
    "# invert the list of backpointers\n",
    "backpointer.reverse()\n",
    "\n",
    "# go backwards through the list of backpointers\n",
    "# (or in this case forward, because we have inverter the backpointer list)\n",
    "# in each case:\n",
    "# the following best tag is the one listed under\n",
    "# the backpointer for the current best tag\n",
    "current_best_tag = best_previous\n",
    "for bp in backpointer:\n",
    "    best_tagsequence.append(bp[current_best_tag])\n",
    "    current_best_tag = bp[current_best_tag]\n",
    "\n",
    "best_tagsequence.reverse()\n",
    "print( \"The sentence was:\", end = \" \")\n",
    "for w in sentence: print( w, end = \" \")\n",
    "print(\"\\n\")\n",
    "print( \"The best tag sequence is:\", end = \" \")\n",
    "for t in best_tagsequence: print (t, end = \" \")\n",
    "print(\"\\n\")\n",
    "print( \"The probability of the best tag sequence is:\", prob_tagsequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLtm3qKYsDVZ"
   },
   "source": [
    "The code is implemented by [Katrin Erk](http://www.katrinerk.com/courses/python-worksheets/hidden-markov-models-for-pos-tagging-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cY7cOjnUvMc"
   },
   "source": [
    "##  Train HMM Tagger with NLTK HMM Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "S8akyRu6qvcr",
    "outputId": "c705a115-b23e-456b-f799-1c720eb21430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n"
     ]
    }
   ],
   "source": [
    "# Pretagged training data\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "\n",
    "print(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ftW_G61yqv_T",
    "outputId": "4f21995d-0286-48fe-ebf4-92947daaa4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HiddenMarkovModelTagger 472 states and 56057 output symbols>\n",
      "[('This', 'DT'), ('race', 'NN'), ('is', 'BEZ'), ('awesome', 'JJ'), (',', ','), ('I', 'PPSS'), ('want', 'VB'), ('to', 'TO'), ('race', 'VB'), ('too', 'QL')]\n"
     ]
    }
   ],
   "source": [
    "# Import HMM module\n",
    "from nltk.tag import hmm\n",
    "\n",
    "# Setup a trainer with default(None) values\n",
    "# And train with the data\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "trained_tagger = trainer.train_supervised(brown_tagged_sents)\n",
    "\n",
    "print (trained_tagger)\n",
    "# Prints the basic data about the tagger\n",
    "\n",
    "tokens = word_tokenize(\"This race is awesome, I want to race too\")\n",
    "print(trained_tagger.tag(tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxHS0Ji2p5X3"
   },
   "source": [
    "# LSTM based POS Tagger (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSHk_WHa_bfV"
   },
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "kYLogDRZH1cd",
    "outputId": "348f6cfd-8a9d-4eb4-e84e-39d289fb795d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "-m4-XQjo6Qu5",
    "outputId": "78c24a1d-6424-4075-feda-5a7725a2738c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vnE3URn56Qux",
    "outputId": "0973e11d-efd1-4ec4-d7a8-f8a4371cf000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorillard' 'Inc.' ',' 'the' 'unit' 'of' 'New' 'York-based' 'Loews'\n",
      " 'Corp.' 'that' '*T*-2' 'makes' 'Kent' 'cigarettes' ',' 'stopped' 'using'\n",
      " 'crocidolite' 'in' 'its' 'Micronite' 'cigarette' 'filters' 'in' '1956'\n",
      " '.']\n",
      "['NNP' 'NNP' ',' 'DT' 'NN' 'IN' 'JJ' 'JJ' 'NNP' 'NNP' 'WDT' '-NONE-' 'VBZ'\n",
      " 'NNP' 'NNS' ',' 'VBD' 'VBG' 'NN' 'IN' 'PRP$' 'NN' 'NN' 'NNS' 'IN' 'CD'\n",
      " '.']\n"
     ]
    }
   ],
   "source": [
    "sentences, sentence_tags =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    " \n",
    "print(sentences[5])\n",
    "print(sentence_tags[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tn34twJZ6Qut"
   },
   "outputs": [],
   "source": [
    "(train_sentences, \n",
    " test_sentences, \n",
    " train_tags, \n",
    " test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKCc8BbR_l87"
   },
   "source": [
    "### Making vocabs with special tokens: padding (PAD) and unknown (OOV)\n",
    "\n",
    "*OOV: Out Of Vocabulary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CY1FlDIo6Quo"
   },
   "outputs": [],
   "source": [
    "words, tags = set([]), set([])\n",
    " \n",
    "for s in train_sentences:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in train_tags:\n",
    "    for t in ts:\n",
    "        tags.add(t)\n",
    "\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 2 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding\n",
    "tag2index['-OOV-'] = 1  # The special value used for OOVs\n",
    "\n",
    "def tag_to_index(tag):\n",
    "    if tag in tag2index:\n",
    "        return tag2index[tag]\n",
    "    else:\n",
    "        return tag2index['-OOV-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "gj_T_YTL6Qug",
    "outputId": "5b1411a6-956e-41d4-9b44-3d093f73249f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2179, 10143, 1618, 8819, 1750, 9622, 8819, 513, 8700, 7238, 8819, 9097, 3892, 8416, 3654, 9282, 6257, 4124, 1186, 8978, 2918, 1037, 180, 7218, 8030, 8267, 6792, 3892, 6542, 9276, 3654, 9282, 577, 5471, 1770, 2885, 2310]\n",
      "[7461, 5828, 8819, 607, 5789, 404, 8819, 9279, 3237, 7218, 2918, 1, 6542, 6534, 5468, 1, 6420, 8180, 226, 6792, 7218, 2918, 219, 9282, 5468, 2918, 1968, 3772, 3892, 8230, 3892, 2918, 1, 3163, 8819, 2000, 3038, 7417, 1186, 8978, 2310]\n",
      "[31, 33, 41, 28, 5, 5, 28, 30, 3, 41, 28, 33, 34, 24, 34, 33, 3, 35, 25, 25, 37, 20, 18, 25, 34, 5, 10, 34, 33, 41, 34, 33, 5, 41, 47, 41, 15]\n",
      "[5, 5, 28, 34, 4, 41, 28, 30, 18, 25, 37, 20, 33, 41, 41, 3, 34, 3, 35, 10, 25, 37, 20, 33, 41, 37, 41, 41, 31, 31, 34, 37, 3, 35, 28, 5, 5, 27, 25, 25, 15]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
    "\n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    train_sentences_X.append(s_int)\n",
    "\n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "for s in train_tags:\n",
    "    train_tags_y.append([tag_to_index(t) for t in s])\n",
    "\n",
    "for s in test_tags:\n",
    "    test_tags_y.append([tag_to_index(t) for t in s])\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eb-SNMWFdxG"
   },
   "source": [
    "### Getting max length of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Q9US1y_a6QuT",
    "outputId": "65526e5b-1e38-432a-ca8a-b7839716d395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xz89piaI6QuO",
    "outputId": "a43e1374-e410-4051-acb4-0ed47f898d8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BjTDYN3sFtet"
   },
   "source": [
    "## Keras Model (Bidirectional LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "-8F4UwEm6Qt-",
    "outputId": "d2caab24-23ab-4bb5-c422-da976214c22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 271, 128)          1300352   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 271, 512)          788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 271, 48)           24624     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 271, 48)           0         \n",
      "=================================================================\n",
      "Total params: 2,113,456\n",
      "Trainable params: 2,113,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xa9rHq0I6Qtx"
   },
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKCjdEcx_YbB"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1619
    },
    "colab_type": "code",
    "id": "alfJSo8C6Qtj",
    "outputId": "94ddd975-87f2-419a-91ac-7d9d049e0212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 2504 samples, validate on 627 samples\n",
      "Epoch 1/40\n",
      "2504/2504 [==============================] - 28s 11ms/step - loss: 1.3734 - acc: 0.8587 - val_loss: 0.3907 - val_acc: 0.9073\n",
      "Epoch 2/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.3464 - acc: 0.9048 - val_loss: 0.3155 - val_acc: 0.9073\n",
      "Epoch 3/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.3166 - acc: 0.9079 - val_loss: 0.3026 - val_acc: 0.9183\n",
      "Epoch 4/40\n",
      "2504/2504 [==============================] - 24s 9ms/step - loss: 0.3055 - acc: 0.9170 - val_loss: 0.2937 - val_acc: 0.9188\n",
      "Epoch 5/40\n",
      "2504/2504 [==============================] - 24s 9ms/step - loss: 0.2965 - acc: 0.9170 - val_loss: 0.2861 - val_acc: 0.9188\n",
      "Epoch 6/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2882 - acc: 0.9170 - val_loss: 0.2787 - val_acc: 0.9196\n",
      "Epoch 7/40\n",
      "2504/2504 [==============================] - 24s 9ms/step - loss: 0.2813 - acc: 0.9187 - val_loss: 0.2730 - val_acc: 0.9227\n",
      "Epoch 8/40\n",
      "2504/2504 [==============================] - 24s 9ms/step - loss: 0.2844 - acc: 0.9187 - val_loss: 0.2928 - val_acc: 0.9157\n",
      "Epoch 9/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2849 - acc: 0.9194 - val_loss: 0.2722 - val_acc: 0.9189\n",
      "Epoch 10/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2737 - acc: 0.9227 - val_loss: 0.2645 - val_acc: 0.9270\n",
      "Epoch 11/40\n",
      "2504/2504 [==============================] - 25s 10ms/step - loss: 0.2667 - acc: 0.9258 - val_loss: 0.2587 - val_acc: 0.9278\n",
      "Epoch 12/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2596 - acc: 0.9303 - val_loss: 0.2501 - val_acc: 0.9339\n",
      "Epoch 13/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2502 - acc: 0.9353 - val_loss: 0.2386 - val_acc: 0.9377\n",
      "Epoch 14/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2343 - acc: 0.9412 - val_loss: 0.2215 - val_acc: 0.9458\n",
      "Epoch 15/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.2125 - acc: 0.9474 - val_loss: 0.1986 - val_acc: 0.9491\n",
      "Epoch 16/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.1866 - acc: 0.9518 - val_loss: 0.1744 - val_acc: 0.9536\n",
      "Epoch 17/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.1607 - acc: 0.9571 - val_loss: 0.1515 - val_acc: 0.9585\n",
      "Epoch 18/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.1376 - acc: 0.9639 - val_loss: 0.1322 - val_acc: 0.9643\n",
      "Epoch 19/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.1172 - acc: 0.9704 - val_loss: 0.1157 - val_acc: 0.9705\n",
      "Epoch 20/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0993 - acc: 0.9761 - val_loss: 0.1015 - val_acc: 0.9743\n",
      "Epoch 21/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0840 - acc: 0.9806 - val_loss: 0.0892 - val_acc: 0.9782\n",
      "Epoch 22/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0706 - acc: 0.9847 - val_loss: 0.0790 - val_acc: 0.9813\n",
      "Epoch 23/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0591 - acc: 0.9880 - val_loss: 0.0700 - val_acc: 0.9839\n",
      "Epoch 24/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0494 - acc: 0.9904 - val_loss: 0.0624 - val_acc: 0.9857\n",
      "Epoch 25/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0413 - acc: 0.9921 - val_loss: 0.0566 - val_acc: 0.9870\n",
      "Epoch 26/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0348 - acc: 0.9934 - val_loss: 0.0518 - val_acc: 0.9879\n",
      "Epoch 27/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0297 - acc: 0.9944 - val_loss: 0.0484 - val_acc: 0.9885\n",
      "Epoch 28/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0256 - acc: 0.9951 - val_loss: 0.0457 - val_acc: 0.9889\n",
      "Epoch 29/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0224 - acc: 0.9957 - val_loss: 0.0435 - val_acc: 0.9893\n",
      "Epoch 30/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0198 - acc: 0.9961 - val_loss: 0.0418 - val_acc: 0.9898\n",
      "Epoch 31/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0178 - acc: 0.9965 - val_loss: 0.0409 - val_acc: 0.9899\n",
      "Epoch 32/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0161 - acc: 0.9968 - val_loss: 0.0398 - val_acc: 0.9900\n",
      "Epoch 33/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0147 - acc: 0.9970 - val_loss: 0.0393 - val_acc: 0.9902\n",
      "Epoch 34/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0134 - acc: 0.9973 - val_loss: 0.0382 - val_acc: 0.9906\n",
      "Epoch 35/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0124 - acc: 0.9975 - val_loss: 0.0379 - val_acc: 0.9906\n",
      "Epoch 36/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.0375 - val_acc: 0.9906\n",
      "Epoch 37/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0373 - val_acc: 0.9907\n",
      "Epoch 38/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0099 - acc: 0.9980 - val_loss: 0.0370 - val_acc: 0.9907\n",
      "Epoch 39/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0093 - acc: 0.9981 - val_loss: 0.0377 - val_acc: 0.9907\n",
      "Epoch 40/40\n",
      "2504/2504 [==============================] - 24s 10ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0372 - val_acc: 0.9906\n",
      "783/783 [==============================] - 11s 14ms/step\n",
      "acc: 99.05510569136415\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "\n",
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)\n",
    "\n",
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\") \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpkj0iSKDSMr"
   },
   "source": [
    "## Testing with sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "llp22Ws3_S7H",
    "outputId": "fe8e2d5a-9690-433b-81b0-c04fbf494af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'race', 'is', 'awesome', ',', 'I', 'want', 'to', 'race', 'too', '.']]\n",
      "[['DT', 'NN', 'VBZ', 'NN', ',', 'PRP', 'VBP', 'TO', 'NN', 'RB', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    word_tokenize(\"This race is awesome, I want to race too.\")\n",
    "]\n",
    "\n",
    "# Converting sentence (tokens) word to index\n",
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    "\n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "#decode the result to have actual tags\n",
    "def decode_result(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences\n",
    "\n",
    "\n",
    "predictions = model.predict(test_samples_X)\n",
    "\n",
    "print(test_samples)\n",
    "print(decode_result(predictions, {i: t for t, i in tag2index.items()}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4no4rxxG8ur"
   },
   "source": [
    "# Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ujtOvVQG_Kh"
   },
   "source": [
    "In this exercise, you are required to implement a program to retrieve top 10 frequent words for adjective tag and noun tag.  You are free to choose training dataset but the POS tagger should be either HMM or LSTM based.\n",
    "\n",
    "\n",
    "For counting words, you can use [FreqDist()](http://www.nltk.org/api/nltk.html?highlight=freqdist) in  NLTK Probability module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkGKNMQNZYdF"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "from nltk.tag import hmm\n",
    "\n",
    "\n",
    "class POSWordCounter():\n",
    "    \n",
    "    _word = \"\"\n",
    "    _trained_tagger = None\n",
    "    \n",
    "    noun_words = []\n",
    "    adj_words = []\n",
    "\n",
    "    # add more class attributes if required\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, word):\n",
    "        self._word = word\n",
    "        \n",
    "        \n",
    "    def train_pos_tagger(word):\n",
    "\n",
    "        \n",
    "    def count_words():\n",
    "        \n",
    "\n",
    "    def get_top5_noun_words():\n",
    "\n",
    "        return \n",
    "\n",
    "    def get_top5_adj_words():\n",
    "\n",
    "        return \n",
    "\n",
    "    # add more class methods if required\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "word = \"University of Sydney\"\n",
    "pwc = POSWordCounter(word)\n",
    "pwc.train_pos_tagger()\n",
    "pwc.count_words()\n",
    "\n",
    "print(pwc.get_top5_noun_words())\n",
    "print(pwc.get_top5_adj_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOMryoIbD4YL"
   },
   "source": [
    "\n",
    "## Sample Ouput\n",
    "```\n",
    "[('university', 30), ('campus', 8), ('cent', 4), ('program', 3), ('faculty', 3)]\n",
    "[('Australian', 3), ('new', 3), ('rare', 3), ('current', 2), ('senior', 2)]\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab06.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
